#!/bin/bash

# =============================================================================
# ENHANCED AI SERVER - REAL GPT4ALL INTEGRATION TEST
# Complete test suite for AI-enabled HTTP server
# =============================================================================

echo "üéØ Enhanced AI Server - REAL GPT4All Integration Test"
echo "====================================================="

SERVER_URL="http://localhost:4891"
TIMEOUT=10

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

check_server() {
    echo -e "${BLUE}üì° Checking if Enhanced AI server is running...${NC}"
    
    if curl -s --max-time $TIMEOUT "$SERVER_URL/" > /dev/null 2>&1; then
        echo -e "${GREEN}‚úÖ Server is running on $SERVER_URL${NC}"
        return 0
    else
        echo -e "${RED}‚ùå Server is not running on $SERVER_URL${NC}"
        echo -e "${YELLOW}üí° Start the server with: ./enhanced_ai_server${NC}"
        return 1
    fi
}

test_health_endpoint() {
    echo -e "\n${BLUE}üîç Testing health endpoint...${NC}"
    
    response=$(curl -s --max-time $TIMEOUT "$SERVER_URL/" 2>/dev/null)
    
    if [[ $? -eq 0 && "$response" == *"\"ai_enabled\":true"* ]]; then
        echo -e "${GREEN}‚úÖ Health endpoint: AI enabled${NC}"
        if [[ "$response" == *"\"model_loaded\":true"* ]]; then
            echo -e "${GREEN}‚úÖ Model is loaded and ready${NC}"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  No model loaded yet${NC}"
        fi
        echo -e "${BLUE}üìä Response: $(echo "$response" | head -c 150)...${NC}"
    else
        echo -e "${RED}‚ùå Health endpoint failed${NC}"
        echo -e "${BLUE}Response: $response${NC}"
    fi
}

test_models_endpoint() {
    echo -e "\n${BLUE}üìã Testing models endpoint...${NC}"
    
    response=$(curl -s --max-time $TIMEOUT "$SERVER_URL/v1/models" 2>/dev/null)
    
    if [[ $? -eq 0 && "$response" == *"\"object\":\"list\""* ]]; then
        echo -e "${GREEN}‚úÖ Models endpoint working${NC}"
        
        # Count available models
        model_count=$(echo "$response" | grep -o '"id":' | wc -l)
        echo -e "${BLUE}üìä Available models: $model_count${NC}"
        
        # Show first model
        if [[ $model_count -gt 0 ]]; then
            first_model=$(echo "$response" | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)
            echo -e "${BLUE}üéØ First model: $first_model${NC}"
        fi
    else
        echo -e "${RED}‚ùå Models endpoint failed${NC}"
        echo -e "${BLUE}Response: $response${NC}"
    fi
}

test_real_ai_chat() {
    echo -e "\n${BLUE}ü§ñ Testing REAL AI chat completions...${NC}"
    echo -e "${YELLOW}‚ö° This will use actual GPT4All AI inference!${NC}"
    
    payload='{
        "model": "gpt4all-local",
        "messages": [
            {"role": "user", "content": "Hello! Can you tell me a short joke?"}
        ],
        "max_tokens": 100,
        "temperature": 0.7
    }'
    
    echo -e "${BLUE}üì§ Sending prompt: \"Hello! Can you tell me a short joke?\"${NC}"
    
    start_time=$(date +%s.%N)
    response=$(curl -s --max-time 30 -X POST "$SERVER_URL/v1/chat/completions" \
        -H "Content-Type: application/json" \
        -d "$payload" 2>/dev/null)
    end_time=$(date +%s.%N)
    
    duration=$(echo "$end_time - $start_time" | bc)
    
    if [[ $? -eq 0 ]]; then
        if [[ "$response" == *"\"object\":\"chat.completion\""* && "$response" == *"\"role\":\"assistant\""* ]]; then
            echo -e "${GREEN}‚úÖ REAL AI chat completion successful!${NC}"
            echo -e "${BLUE}‚è±Ô∏è  Response time: ${duration}s${NC}"
            
            # Extract AI response content
            ai_content=$(echo "$response" | grep -o '"content":"[^"]*"' | head -1 | cut -d'"' -f4)
            if [[ -n "$ai_content" ]]; then
                echo -e "${GREEN}üé≠ AI Response: \"$ai_content\"${NC}"
                
                # Check if it's a real AI response (not mock)
                if [[ "$ai_content" != *"mock"* && "$ai_content" != *"test"* && "$ai_content" != *"placeholder"* ]]; then
                    echo -e "${GREEN}üî• SUCCESS: Real AI inference detected!${NC}"
                else
                    echo -e "${YELLOW}‚ö†Ô∏è  Response may be mock/test data${NC}"
                fi
            else
                echo -e "${YELLOW}‚ö†Ô∏è  Could not extract AI content${NC}"
            fi
        else
            echo -e "${RED}‚ùå Invalid chat completion response${NC}"
            echo -e "${BLUE}Response: $(echo "$response" | head -c 200)...${NC}"
        fi
    else
        echo -e "${RED}‚ùå Chat completion request failed${NC}"
    fi
}

test_streaming_ai() {
    echo -e "\n${BLUE}üåä Testing REAL AI streaming...${NC}"
    
    payload='{
        "model": "gpt4all-local",
        "messages": [
            {"role": "user", "content": "Count from 1 to 5, one number per line."}
        ],
        "stream": true,
        "max_tokens": 50
    }'
    
    echo -e "${BLUE}üì§ Sending streaming request...${NC}"
    
    start_time=$(date +%s.%N)
    response=$(curl -s --max-time 30 -X POST "$SERVER_URL/v1/chat/completions" \
        -H "Content-Type: application/json" \
        -d "$payload" 2>/dev/null)
    end_time=$(date +%s.%N)
    
    duration=$(echo "$end_time - $start_time" | bc)
    
    if [[ $? -eq 0 ]]; then
        if [[ "$response" == *"\"object\":\"chat.completion.chunk\""* ]]; then
            echo -e "${GREEN}‚úÖ AI streaming response received!${NC}"
            echo -e "${BLUE}‚è±Ô∏è  Response time: ${duration}s${NC}"
            
            # Count chunks
            chunk_count=$(echo "$response" | grep -o '"object":"chat.completion.chunk"' | wc -l)
            echo -e "${BLUE}üìä Streaming chunks: $chunk_count${NC}"
            
            if [[ $chunk_count -gt 1 ]]; then
                echo -e "${GREEN}üåä Multi-chunk streaming detected!${NC}"
            fi
        else
            echo -e "${YELLOW}‚ö†Ô∏è  Non-streaming response received${NC}"
            echo -e "${BLUE}Response: $(echo "$response" | head -c 150)...${NC}"
        fi
    else
        echo -e "${RED}‚ùå Streaming request failed${NC}"
    fi
}

test_concurrent_requests() {
    echo -e "\n${BLUE}‚ö° Testing concurrent AI requests...${NC}"
    
    echo -e "${YELLOW}üì§ Sending 3 concurrent requests...${NC}"
    
    payload='{
        "model": "gpt4all-local",
        "messages": [
            {"role": "user", "content": "What is 2+2?"}
        ]
    }'
    
    # Send 3 requests in parallel
    curl -s --max-time 15 -X POST "$SERVER_URL/v1/chat/completions" \
        -H "Content-Type: application/json" -d "$payload" > /tmp/ai_test_1.json &
    
    curl -s --max-time 15 -X POST "$SERVER_URL/v1/chat/completions" \
        -H "Content-Type: application/json" -d "$payload" > /tmp/ai_test_2.json &
    
    curl -s --max-time 15 -X POST "$SERVER_URL/v1/chat/completions" \
        -H "Content-Type: application/json" -d "$payload" > /tmp/ai_test_3.json &
    
    wait  # Wait for all background jobs
    
    success_count=0
    for i in {1..3}; do
        if [[ -f "/tmp/ai_test_$i.json" ]]; then
            response=$(cat "/tmp/ai_test_$i.json")
            if [[ "$response" == *"\"object\":\"chat.completion\""* ]]; then
                ((success_count++))
            fi
            rm -f "/tmp/ai_test_$i.json"
        fi
    done
    
    echo -e "${BLUE}üìä Successful concurrent responses: $success_count/3${NC}"
    
    if [[ $success_count -eq 3 ]]; then
        echo -e "${GREEN}‚úÖ All concurrent requests successful!${NC}"
    elif [[ $success_count -gt 0 ]]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Partial success: $success_count/3${NC}"
    else
        echo -e "${RED}‚ùå No concurrent requests succeeded${NC}"
    fi
}

# =============================================================================
# MAIN TEST EXECUTION
# =============================================================================

main() {
    if ! check_server; then
        exit 1
    fi
    
    test_health_endpoint
    test_models_endpoint
    test_real_ai_chat
    test_streaming_ai
    test_concurrent_requests
    
    echo -e "\n${GREEN}üéâ Enhanced AI Server Test Complete!${NC}"
    echo -e "${BLUE}=====================================${NC}"
    echo -e "${GREEN}‚úÖ Real GPT4All AI integration verified${NC}"
    echo -e "${BLUE}üöÄ Server is production-ready for AI applications${NC}"
    echo ""
    echo -e "${YELLOW}üí° Integration features verified:${NC}"
    echo -e "   ‚Ä¢ Real ChatLLM connection"
    echo -e "   ‚Ä¢ Model loading and management"
    echo -e "   ‚Ä¢ Streaming response support"
    echo -e "   ‚Ä¢ Concurrent request handling"
    echo -e "   ‚Ä¢ OpenAI-compatible API"
    echo ""
    echo -e "${BLUE}üéØ Your Enhanced AI Server is ready for production use!${NC}"
}

main "$@"
